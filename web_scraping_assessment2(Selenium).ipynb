{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a python program to scrape data for “Data Analyst” Job position in“Bangalore” location. You have to scrape the job-title, job-location, company_name,experience_required. You have to scrape first 10 jobs data.This task will be done in following steps:1. first get the webpage https://www.naukri.com/2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore”in “enter the location” field.3. Then click the search button.4. Then scrape the data for the first 10 jobs results you get.5. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To fill the search box with designation as Data Scientist\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To fill the search box with location as Delhi\n",
    "search_loc = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To click on the button search\n",
    "search_btn = driver.find_element_by_class_name(\"btn\")\n",
    "# or we can use driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Scientist I',\n",
       " 'IDM - Lead Data Scientist',\n",
       " 'Principal Data Scientist',\n",
       " 'Data Scientist - Business Analytics',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Immediately hiring For Data Scientist - (Bangalore)',\n",
       " 'Immediately hiring For Data Scientist - (Bangalore)',\n",
       " 'Senior/Lead Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - SQL/R/Python',\n",
       " 'Data Scientist - Predictive Analytics',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'SENIOR DATA SCIENTIST',\n",
       " 'Senior Data Scientist',\n",
       " 'Immediate job opening - Senior Data Scientist']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To scrape the job title\n",
    "job_title = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title = []\n",
    "for i in job_title:\n",
    "    title.append(i.text)\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Scientist I',\n",
       " 'IDM - Lead Data Scientist',\n",
       " 'Principal Data Scientist',\n",
       " 'Data Scientist - Business Analytics',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Immediately hiring For Data Scientist - (Bangalore)',\n",
       " 'Immediately hiring For Data Scientist - (Bangalore)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles = []\n",
    "for i in range(10):\n",
    "    job_titles.append(title[i])\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_loc = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "job_location = []\n",
    "for i in job_loc:\n",
    "    job_location.append(i.text)\n",
    "location = []\n",
    "for j in range(10):\n",
    "    location.append(job_location[j])\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Philips India Limited',\n",
       " 'Philips India Limited',\n",
       " 'Philips India Limited',\n",
       " 'Philips India Limited',\n",
       " 'Philips India Limited',\n",
       " 'Replicon Software',\n",
       " 'Replicon Software',\n",
       " 'Applied Materials',\n",
       " 'Trigent Software',\n",
       " 'Trigent Software']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_name = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "name = []\n",
    "for i in comp_name:\n",
    "    name.append(i.text)\n",
    "company_name = []\n",
    "for j in range(10):\n",
    "    company_name.append(name[j])\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6-10 Yrs',\n",
       " '10-15 Yrs',\n",
       " '9-13 Yrs',\n",
       " '4-8 Yrs',\n",
       " '2-15 Yrs',\n",
       " '5-10 Yrs',\n",
       " '5-10 Yrs',\n",
       " '2-4 Yrs',\n",
       " '5-8 Yrs',\n",
       " '5-8 Yrs']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "exper = []\n",
    "for i in exp:\n",
    "    exper.append(i.text)\n",
    "experience = []\n",
    "for j in range(10):\n",
    "    experience.append(exper[j])\n",
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDM - Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>10-15 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>9-13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Business Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>2-15 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Replicon Software</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Replicon Software</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Immediately hiring For Data Scientist - (Banga...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Immediately hiring For Data Scientist - (Banga...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                            Senior Data Scientist I   \n",
       "1                          IDM - Lead Data Scientist   \n",
       "2                           Principal Data Scientist   \n",
       "3                Data Scientist - Business Analytics   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8  Immediately hiring For Data Scientist - (Banga...   \n",
       "9  Immediately hiring For Data Scientist - (Banga...   \n",
       "\n",
       "                                            Location                Company  \\\n",
       "0                                Bangalore/Bengaluru  Philips India Limited   \n",
       "1                                Bangalore/Bengaluru  Philips India Limited   \n",
       "2                                Bangalore/Bengaluru  Philips India Limited   \n",
       "3                                Bangalore/Bengaluru  Philips India Limited   \n",
       "4                                Bangalore/Bengaluru  Philips India Limited   \n",
       "5  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...      Replicon Software   \n",
       "6  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...      Replicon Software   \n",
       "7                                Bangalore/Bengaluru      Applied Materials   \n",
       "8                                Bangalore/Bengaluru       Trigent Software   \n",
       "9                                Bangalore/Bengaluru       Trigent Software   \n",
       "\n",
       "  Experience  \n",
       "0   6-10 Yrs  \n",
       "1  10-15 Yrs  \n",
       "2   9-13 Yrs  \n",
       "3    4-8 Yrs  \n",
       "4   2-15 Yrs  \n",
       "5   5-10 Yrs  \n",
       "6   5-10 Yrs  \n",
       "7    2-4 Yrs  \n",
       "8    5-8 Yrs  \n",
       "9    5-8 Yrs  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_Vacany = pd.DataFrame({})\n",
    "Job_Vacany[\"Job Title\"]=job_titles\n",
    "Job_Vacany[\"Location\"]=location\n",
    "Job_Vacany[\"Company\"]=company_name\n",
    "Job_Vacany[\"Experience\"]=experience\n",
    "Job_Vacany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a python program to scrape data for “Data Scientist” Job position in“Bangalore” location. You have to scrape the job-title, job-location,company_name, full job-description. You have to scrape first 10 jobs data.This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter“Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To fill the search box with designation as Data Scientist\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To fill the search box with location as Delhi\n",
    "search_loc = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To click on the button search\n",
    "search_btn = driver.find_element_by_class_name(\"btn\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Scientist I',\n",
       " 'IDM - Lead Data Scientist',\n",
       " 'Principal Data Scientist',\n",
       " 'Data Scientist - Business Analytics',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Immediately hiring For Data Scientist - (Bangalore)',\n",
       " 'Immediately hiring For Data Scientist - (Bangalore)']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title = []\n",
    "for i in job_title:\n",
    "    title.append(i.text)\n",
    "job_titles = []\n",
    "for i in range(10):\n",
    "    job_titles.append(title[i])\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_loc = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "job_location = []\n",
    "for i in job_loc:\n",
    "    job_location.append(i.text)\n",
    "location = []\n",
    "for j in range(10):\n",
    "    location.append(job_location[j])\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Philips India Limited',\n",
       " 'Philips India Limited',\n",
       " 'Philips India Limited',\n",
       " 'Philips India Limited',\n",
       " 'Philips India Limited',\n",
       " 'Replicon Software',\n",
       " 'Replicon Software',\n",
       " 'Applied Materials',\n",
       " 'Trigent Software',\n",
       " 'Trigent Software']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_name = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "name = []\n",
    "for i in comp_name:\n",
    "    name.append(i.text)\n",
    "company_name = []\n",
    "for j in range(10):\n",
    "    company_name.append(name[j])\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-senior-data-scientist-i-philips-india-limited-bangalore-bengaluru-6-to-10-years-250621500799?src=jobsearchDesk&sid=16247722636418824&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-idm-lead-data-scientist-philips-india-limited-bangalore-bengaluru-10-to-15-years-250621500736?src=jobsearchDesk&sid=16247722636418824&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-principal-data-scientist-philips-india-limited-bangalore-bengaluru-9-to-13-years-250621500764?src=jobsearchDesk&sid=16247722636418824&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-business-analytics-philips-india-limited-bangalore-bengaluru-4-to-8-years-250621500272?src=jobsearchDesk&sid=16247722636418824&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-philips-india-limited-bangalore-bengaluru-2-to-15-years-250621500719?src=jobsearchDesk&sid=16247722636418824&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-replicon-software-kolkata-hyderabad-secunderabad-pune-ahmedabad-chennai-bangalore-bengaluru-delhi-ncr-mumbai-all-areas-5-to-10-years-260621603052?src=jobsearchDesk&sid=16247722636418824&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-replicon-software-kolkata-hyderabad-secunderabad-pune-ahmedabad-chennai-bangalore-bengaluru-delhi-ncr-mumbai-all-areas-5-to-10-years-260621003050?src=jobsearchDesk&sid=16247722636418824&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-applied-materials-india-private-limited-bangalore-bengaluru-2-to-4-years-250621903137?src=jobsearchDesk&sid=16247722636418824&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-immediately-hiring-for-data-scientist-bangalore-trigent-software-private-limited-bangalore-bengaluru-5-to-8-years-250621601292?src=jobsearchDesk&sid=16247722636418824&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-immediately-hiring-for-data-scientist-bangalore-trigent-software-private-limited-bangalore-bengaluru-5-to-8-years-250621001290?src=jobsearchDesk&sid=16247722636418824&xp=10&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-lead-data-scientist-aureustech-systems-private-limited-hyderabad-secunderabad-chennai-bangalore-bengaluru-9-to-14-years-230621004832?src=jobsearchDesk&sid=16247722636418824&xp=11&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-sa-technologies-bangalore-bengaluru-4-to-5-years-250621501585?src=jobsearchDesk&sid=16247722636418824&xp=12&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-sql-r-python-imindyourbusiness-bangalore-bengaluru-4-to-8-years-250621902854?src=jobsearchDesk&sid=16247722636418824&xp=13&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-predictive-analytics-talentstack-bangalore-bengaluru-1-to-3-years-250621902694?src=jobsearchDesk&sid=16247722636418824&xp=14&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-kwalee-india-pvt-ltd-bangalore-bengaluru-5-to-10-years-260321000780?src=jobsearchDesk&sid=16247722636418824&xp=15&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-bankbazaar-com-a-a-dukaan-financial-services-pvt-ltd-bangalore-bengaluru-5-to-7-years-040321006895?src=jobsearchDesk&sid=16247722636418824&xp=16&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-happiest-minds-technologies-pvt-ltd-bangalore-bengaluru-5-to-10-years-220621501398?src=jobsearchDesk&sid=16247722636418824&xp=17&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-zazmic-india-private-limited-kolkata-hyderabad-secunderabad-pune-ahmedabad-chennai-bangalore-bengaluru-delhi-ncr-mumbai-all-areas-3-to-8-years-210621007920?src=jobsearchDesk&sid=16247722636418824&xp=18&px=1',\n",
       " 'https://www.naukri.com/job-listings-immediate-opening-senior-data-scientist-redbus-in-ibibo-group-private-limited-bangalore-bengaluru-5-to-8-years-140621005528?src=jobsearchDesk&sid=16247722636418824&xp=19&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-fractal-analytics-ltd-mumbai-gurgaon-gurugram-bangalore-bengaluru-5-to-9-years-140621500966?src=jobsearchDesk&sid=16247722636418824&xp=20&px=1']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To Scrape data from inside\n",
    "# First we need to extract the links\n",
    "jobs_url = []\n",
    "url = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "# the xpath is that of the job title, because clicking on job title gives the description which is inside\n",
    "for i in url:\n",
    "    jobs_url.append(i.get_attribute('href'))\n",
    "jobs_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job Responsibilities Use predictive modeling to increase and optimize customer experiences, revenue generation, campaign optimization and other business outcomes Work with product management to develop data use cases and embed predictive models in workflows on resource constrained platforms and cloud enabled. Selecting features, building and optimizing classifiers using machine learning and deep learning techniques Collaborates with Data Engineers to enhance data collection and ingestion/curation techniques to include information that is relevant for building analytic systems Processing, cleansing, and verifying the integrity of data used for analysis Develop processes and tools to monitor and analyze model performance and data accuracy. Life cycle management of predictive models. Adherence to compliance procedures in accordance with regulatory standards, requirements, and policies. Managing and designing the reporting environment, including data sources security, and metadata. Job Qualifications: Master s degree or PhD in Computer Science, Information management, Statistics or related field, with 10+ years of experience in the Consumer or Healthcare industry manipulating data sets and building predictive models with focus on product development Experience in statistical modelling, machine learning, data mining, unstructured data analytics and natural language processing. Sound understanding of - Bayesian Modelling, Classification Models, Cluster Analysis, Neural Network, Nonparametric Methods, Multivariate Statistics, etc. Strong hands on knowledge of ML techniques like regression algorithms, K-NN, Na ve Bayes, SVM and ensemble techniques like Random forest, AdaBoost etc Having strong knowledge in unsupervised learning algorithms using Neural networks and Deep-Learning Strong knowledge in Data Wrangling and Exploration techniques to identify the patterns, trends and outliners. Deep knowledge and practical experience with data science toolkits, such as NumPy, Pandas, scikit-learn or equivalent Experience with data visualization tools, such as QlikView, Matplotlib, seaborn or equivalent tools. Proficiency in using query languages, such as SQL, PL/SQL Hands on experience in the one or more databases like Hadoop, AWS Redshift, Snowflake etc. Good applied statistics skills, such as distributions, statistical testing, regression, etc. Good ETL scripting and programming skills, such as Python, R or Scala to integrate developed solution into the proposition. A team player capable of working and integrating across cross-functional team for implementing project requirements. Experience in technical requirements gathering and documentation. Ability to work effectively and independently in a fast-paced global collaborative agile team environment with tight deadlines A flexible, pragmatic and collaborative team player with innate ability to engage with stakeholders at all levels in the organization. A self-starter with high levels of drive, energy, resilience and a desire for professional excellence with a passion for data and data science',\n",
       " 'Your responsibilities Ensure strategic direction for data science capabilities for Philips is created and kept up to date on a regular basis Continuously evaluate the latest techniques in Artificial intelligence, machine learning, robotics, statistical analysis Implement advanced algorithms for business problems based on statistical analysis, coding, deep learning, advanced data mining techniques etc. Develop new algorithms if necessary, to bring predictive, advanced statistics / learning based solutions Develop algorithms to further automate processes and feed insights back into PIL for better business outcome Co-create with business / market / functions or IT platforms on requirements Ensure quality of data and solution developed Lead and drive data mining, creating algorithms, collection of data, collection of procedures during the design, build phases of a project Lead and drive in deploy and testing of the solutions and insights Spot and evaluate emerging/cutting edge, open source, data science/machine learning libraries You are part of: You will be part of Group IT , Information and Data Management team that drives business impact through Data Science and Advanced analytics. A team that instigates collaboration across diverse teams globally to manage Data as an asset at Philips. Core competencies needed to be successful: A Master s Degree or PhD in Computer Science, Econometrics, Artificial Intelligence, Applied Mathematics, Statistics or equivalent; 10-15 years of overall experience in data science, data analytics roles 10+ years of experience in multiple of machine learning, data mining, deep learning, artificial intelligence, pattern recognition areas Experience in driving implementation of solutions, data and algorithms on data warehouse and lakes like Azure , AWS, SQL etc Demonstrable advanced programming experience in Python or another programming language such as Azure ML/R/Python etc ; Strong analytical and social skills and the capability to translate data intelligence into valuable insights for the senior stakeholders in the company Ability to formulate multiple complex business problems into hypothesis and proof of concepts for testing Manage Projects and lead a sub-portfolio of data science project teams to deliver results Coach, Guide and direct teams of internal and vendor resources Collaborate across IT platform teams to deploy solutions and drive continuous improvements Manage senior stakeholder in the company in a matrix organization i.e. Market / BG / Function leaders',\n",
       " 'In this role, you have the opportunity to Provide data science solutions using advanced techniques, tools and methods to complex business problems. Create and maintain standards around data science for the company. Partner with businesses, markets and functions. Reporting Head of Information Data Management   You are responsible for Co-create with business / market / functions or IT platforms on data science projects to meet the business need for insights and analytics using sophisticated data science techniques i.e. automation, crunching big data sets, machine learning or AI Setup projects to drive the business needs Participate in budgeting cycle, leading resources and running vendors Work on continuously updating data science strategy including evaluate emerging/cutting edge, open source, data science/machine learning libraries/big data platforms Strong proven experience in solving business problems through data science techniques, statistical modeling where simple analysis will not be sufficient Provide technical and people leadership to the data science team Ability to formulate multiple sophisticated business problems into hypothesis and proof of concepts for testing Coach, Guide and lead teams of internal and vendor resources Direct a team of 10-12 FTE data scientists and their priorities together with the partners and data information strategy Lead PL for the sub-department and the data science project portfolio Lead senior partner in the company in a matrix organization up to Executive committee levels, Market / BG / Function leaders Formulate strategies for incorporating new, latest and cutting-edge techniques and tools To succeed in this role, you should have the following skills and experience Demonstrable sophisticated programming experience in Python or another programming language such as Java/C/C++/R; Strong analytical and interpersonal skills and the capability to translate data intelligence into valuable insights for the senior partners in the company Experience in data analytics and in statistical (regression, clustering and classification), descriptive and diagnosis methods; knowledge of forecasting methods A Master s Degree or PhD in Computer Science, Econometrics, Artificial Intelligence, Applied Mathematics, Statistics or equivalent; Certifications or training in leadership MBA is a plus 15+ years of overall experience in data science, data analytics roles proven experience in multiple of machine learning, data mining, deep learning, artificial intelligence, pattern recognition areas demonstrated ability in creating and leading data science and analytics teams validated experience in creating and leading data science and / or data analytics strategy demonstrated ability in working in multinational companies with matrix structures including handling conflicting priorities from multiple partners',\n",
       " 'Support business in their decision making needs (Operational/ Strategic) by providing insights from Data. Assess solutions for business opportunities by leveraging data (Transactional Data/ Big Data, External and Internal Data, Structured and Unstructured Data) and analytics methods. Provide consulting, advice, training and support in analytics. Furthermore, will build the application related part of analytics knowledge base in the organization domain. Deliver high impact Business insights enabled by Analytics to various functions under the Philips Group Operations. (Markets/ BGs/ Functions would also be consumers of the related Insights from Group Operations) Drive Digital Innovation and deliver Value services to enable the Group Operations Transformation agenda. Enable improvement programs across Philips Sites- using levers such as process automation, digital technologies, analytics, artificial intelligence, etc Harmonize and optimize various Analytics efforts happening under the wider Group Operations to maximize ROI from data analytics for Philips Key Areas of Responsibilities Expertise in analytics techniques/ methods and tools; Expertise in translating business requirements in to analytics and vice versa; strong execution and drive for results; focus on customers; change management skills; E2E operational excellence. Analytical bent of mind Expertize in analytics solutions design, development and deployment Expertize in predictive analytics techniques, and data mining Experience in the areas of analytics, exposure to emerging digital technologies/ landscape. (eg Cloud computing, designing and embedding predictive analytics models into workflows/ processes) Expertize in R, Python tools Expertize in Machine learning AI techniques Ability to manage stakeholders within the organisation Ability to present facts based on data and in working with very large quantum of data Have Business context across the multiple functions in an Organization - accelerating the ability to connect the dots across the breadth depth of large Organizations to enable Business results Experience Qualifications Ability to communicate clearly (oral, written and remote) to remote audience with clear business articulation Expertise in multiple tools and techniques Understands and supports many business processes with analytics solutions/ deliveries Managing direct and indirect stakeholders (support functions) like Finance, IT etc. Collaborates and influences with known stakeholders Identify and replicate best practices across the domain/tools techniques Keep abreast with latest develop in analytics domain, emerging technology Advises business champions in the domain where analytics can contribute Year of industry Exp: 8 10 Years; Relevant Exp in analytics domain: 5+ years',\n",
       " 'In this role, you have the opportunity to Provide data science solutions using advanced techniques, tools and methods to complex business problems. Create and maintain standards around data science for the company. Partner with businesses, markets and functions. You are responsible for Co-create with business / market / functions or IT platforms on requirements Interpret and analyze data problems and come up with viable solutions, hypothesis and proof of concepts Ensure quality of data and solution developed Lead and drive data mining, creating algorithms, collection of data, collection of procedures during the design, build phases of a project Lead and drive in deploy and testing of the solutions and insights Working with big data and databases Provide support to inexperienced analysts Spot and evaluate emerging/cutting edge, open source, data science/machine learning libraries To succeed in this role, you should have the following skills and experience Demonstrable advanced programming experience in Python or another programming language such as Java/C/C++/R; Strong analytical and social skills and the capability to translate data intelligence into valuable insights for the senior stakeholders in the company Experience in data analytics and in statistical (regression, clustering and classification), descriptive and diagnosis methods; knowledge of forecasting methods Ability to formulate multiple complex business problems into hypothesis and proof of concepts for testing Coach, Guide and direct teams of internal and vendor resources Manage and lead a sub-portfolio of data science projects Manage data science project budgets for sub-areas Manage senior stakeholder in the company in a matrix organization i.e. Market / BG / Function leaders A Master s Degree or PhD in Computer Science, Econometrics, Artificial Intelligence, Applied Mathematics, Statistics or equivalent; 10-15 years of overall experience in data science, data analytics roles 10+ years of experience in multiple of machine learning, data mining, deep learning, artificial intelligence, pattern recognition areas 10+ years of experience in using programming languages such as python, R, JAVA, C/C++ etc. to build data science solution 2+ years of experience in working in multinational companies with matrix structures 2+ years of making choices for high impact solution-based data science technique Experience in driving implementation of solutions, data and algorithms on data warehouse and lakes',\n",
       " \"Brief JD Experience: 5 - 10 Yrs   Skills and Qualifications • Bachelor's or Master degree in Statistics, Applied Mathematics or related discipline • Proficiency with data mining, mathematics, and statistical analysis • Advanced pattern recognition and predictive modelling experience • Programming experience (Python, R, etc.)  Preferred Qualifications • 5-10 years experience in data science • Professional certifications • Experience with visualization tools such as PowerBI and Tableau • Experience with NLP/NLU technologies (Amazon Lex, Google DialogFlow, etc) • Experience with AI/ML technologies (Tensorflow, Amazon Sagemaker, etc) • Experience with SQL • Experience working in an Agile environment • A portfolio of relevant work to share  To apply for the role, Share your resumes or refer your friends to Mail ID: damodharan.j@replicon.com\",\n",
       " \"Brief JD Experience: 5 - 10 Yrs   Skills and Qualifications • Bachelor's or Master degree in Statistics, Applied Mathematics or related discipline • Proficiency with data mining, mathematics, and statistical analysis • Advanced pattern recognition and predictive modelling experience • Programming experience (Python, R, etc.)  Preferred Qualifications • 5-10 years experience in data science • Professional certifications • Experience with visualization tools such as PowerBI and Tableau • Experience with NLP/NLU technologies (Amazon Lex, Google DialogFlow, etc) • Experience with AI/ML technologies (Tensorflow, Amazon Sagemaker, etc) • Experience with SQL • Experience working in an Agile environment • A portfolio of relevant work to share  To apply for the role, Share your resumes or refer your friends to Mail ID: damodharan.j@replicon.com\",\n",
       " 'Preferred Qualifications 5-8 years experience in data science. Professional certifications. Experience with visualization tools such as PowerBI and Tableau Experience with NLP/NLU technologies (Amazon Lex, Google DialogFlow, etc) Experience with AI/ML technologies (Tensorflow, Amazon Sagemaker, etc) Experience with SQL Experience working in an Agile environment A portfolio of relevant work to share  Note: If you are interested, kindly revert back with your updated resume ASAP. (sharan_c@trigent.com)',\n",
       " 'Preferred Qualifications 5-8 years experience in data science. Professional certifications. Experience with visualization tools such as PowerBI and Tableau Experience with NLP/NLU technologies (Amazon Lex, Google DialogFlow, etc) Experience with AI/ML technologies (Tensorflow, Amazon Sagemaker, etc) Experience with SQL Experience working in an Agile environment A portfolio of relevant work to share  Note: If you are interested, kindly revert back with your updated resume ASAP. (sharan_c@trigent.com)',\n",
       " 'Responsibilities Identify valuable data sources and automate collection processes Undertake preprocessing of structured and unstructured data Analyze large amounts of information to discover trends and patterns Build predictive models and machine-learning algorithms Combine models through ensemble modeling Present information using data visualization techniques Propose solutions and strategies to business challenges Collaborate with engineering and product development teams  Requirements Proven experience as a Data Scientist or Data Analyst Experience in data mining, Deep Learning Understanding of machine-learning and operations research Experience with NLP Experience with Python Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop) Analytical mind and business acumen Very Strong math skills (e.g. statistics, algebra etc.,) Problem-solving aptitude Excellent communication and presentation skills']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_desc = []\n",
    "for i in jobs_url:\n",
    "    driver.get(i)\n",
    "    job_description = driver.find_elements_by_xpath(\"//div[@class='dang-inner-html']\")\n",
    "    for j in job_description:\n",
    "        job_desc.append(j.text.replace(\"\\n\",\" \"))\n",
    "job_description = []\n",
    "for j in range(10):\n",
    "    job_description .append(job_desc[j])\n",
    "job_description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_description )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Job Responsibilities Use predictive modeling t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDM - Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Your responsibilities Ensure strategic directi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>In this role, you have the opportunity to Prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Business Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Support business in their decision making need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>In this role, you have the opportunity to Prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Replicon Software</td>\n",
       "      <td>Brief JD Experience: 5 - 10 Yrs   Skills and Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Replicon Software</td>\n",
       "      <td>Brief JD Experience: 5 - 10 Yrs   Skills and Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>Preferred Qualifications 5-8 years experience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Immediately hiring For Data Scientist - (Banga...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>Preferred Qualifications 5-8 years experience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Immediately hiring For Data Scientist - (Banga...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>Responsibilities Identify valuable data source...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                            Senior Data Scientist I   \n",
       "1                          IDM - Lead Data Scientist   \n",
       "2                           Principal Data Scientist   \n",
       "3                Data Scientist - Business Analytics   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8  Immediately hiring For Data Scientist - (Banga...   \n",
       "9  Immediately hiring For Data Scientist - (Banga...   \n",
       "\n",
       "                                            Location                Company  \\\n",
       "0                                Bangalore/Bengaluru  Philips India Limited   \n",
       "1                                Bangalore/Bengaluru  Philips India Limited   \n",
       "2                                Bangalore/Bengaluru  Philips India Limited   \n",
       "3                                Bangalore/Bengaluru  Philips India Limited   \n",
       "4                                Bangalore/Bengaluru  Philips India Limited   \n",
       "5  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...      Replicon Software   \n",
       "6  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...      Replicon Software   \n",
       "7                                Bangalore/Bengaluru      Applied Materials   \n",
       "8                                Bangalore/Bengaluru       Trigent Software   \n",
       "9                                Bangalore/Bengaluru       Trigent Software   \n",
       "\n",
       "                                     Job Description  \n",
       "0  Job Responsibilities Use predictive modeling t...  \n",
       "1  Your responsibilities Ensure strategic directi...  \n",
       "2  In this role, you have the opportunity to Prov...  \n",
       "3  Support business in their decision making need...  \n",
       "4  In this role, you have the opportunity to Prov...  \n",
       "5  Brief JD Experience: 5 - 10 Yrs   Skills and Q...  \n",
       "6  Brief JD Experience: 5 - 10 Yrs   Skills and Q...  \n",
       "7  Preferred Qualifications 5-8 years experience ...  \n",
       "8  Preferred Qualifications 5-8 years experience ...  \n",
       "9  Responsibilities Identify valuable data source...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job = pd.DataFrame({})\n",
    "Job[\"Job Title\"]=job_titles\n",
    "Job[\"Location\"]=location\n",
    "Job[\"Company\"]=company_name\n",
    "Job[\"Job Description\"]=job_description\n",
    "Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) You have to use the location and salary filter.You have to scrape data for “Data Scientist” designation for first 10 job results.You have to scrape the job-title, job-location, company_name,experience_required.The location filter to be used is “Delhi/NCR”The salary filter to be used is “3-6” lakhs\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Data Scientist in the search bar\n",
    "search_designation = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for clicking the search button\n",
    "search_click = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying location filter as Delhi/NCR\n",
    "loc_filter = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/i\")\n",
    "loc_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying salary filter as 3-6lakhs\n",
    "salary_filter = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[2]/label/i\")\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Only Fresher / Data Scientist / Data Analyst / Analytics - MNC OSC',\n",
       " 'Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Data Scientist - Text NLP | Noida',\n",
       " 'Data Scientist - Machine Learning/NLP',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - Machine Learning/NLP',\n",
       " 'Data analytics / Data scientist intern (work from Home)',\n",
       " 'Chaayos is Looking For Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'We are hiring- Data Scientist +Python- Noida']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping job title\n",
    "title = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_title = []\n",
    "for i in title:\n",
    "    job_title.append(i.text)\n",
    "job_titles = []\n",
    "for j in range(0,10):\n",
    "    job_titles.append(job_title[j])\n",
    "job_titles   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noida, Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Noida',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Noida',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Kolkata, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'New Delhi',\n",
       " 'Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Noida, Gurgaon/Gurugram, Delhi / NCR']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft fs12 lh16']\")\n",
    "job_location = []\n",
    "for i in location:\n",
    "    job_location.append(i.text)\n",
    "\n",
    "job_locations = []\n",
    "for j in range(2,len(job_location),3):\n",
    "    job_locations.append(job_location[j])\n",
    "locations = []\n",
    "for j in range(0,10):\n",
    "    locations.append(job_locations[j])\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-0 Yrs',\n",
       " '0-3 Yrs',\n",
       " '3-5 Yrs',\n",
       " '2-6 Yrs',\n",
       " '3-8 Yrs',\n",
       " '2-4 Yrs',\n",
       " '0-5 Yrs',\n",
       " '0-5 Yrs',\n",
       " '3-7 Yrs',\n",
       " '4-7 Yrs']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_location\n",
    "experience=[]\n",
    "for i in range(0,len(job_location),3):\n",
    "    experience.append(job_location[i])\n",
    "exp = []\n",
    "for j in range(10):\n",
    "    exp.append(experience[j])\n",
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GABA Consultancy services',\n",
       " 'Inflexion Analytix Private Limited',\n",
       " 'Acidaes Solutions Pvt. Ltd.',\n",
       " 'TalPro',\n",
       " 'NEC CORPORATION INDIA PRIVATE LIMITED',\n",
       " 'TalPro',\n",
       " 'TalkValley LLC',\n",
       " 'Chaayos (Sunshine Teahouse Pvt. Ltd.)',\n",
       " 'Fractal Analytics',\n",
       " 'RANDSTAD INDIA PVT LTD']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_name = []\n",
    "for i in name:\n",
    "    company_name.append(i.text)\n",
    "comp_name = []\n",
    "for j in range(10):\n",
    "    comp_name.append(company_name[j])\n",
    "comp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience Required</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Text NLP | Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Acidaes Solutions Pvt. Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>TalPro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>TalPro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data analytics / Data scientist intern (work f...</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>TalkValley LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chaayos is Looking For Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>Chaayos (Sunshine Teahouse Pvt. Ltd.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We are hiring- Data Scientist +Python- Noida</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "1    Data Scientist / Data Analyst -Business Analyst   \n",
       "2                  Data Scientist - Text NLP | Noida   \n",
       "3              Data Scientist - Machine Learning/NLP   \n",
       "4                                     Data Scientist   \n",
       "5              Data Scientist - Machine Learning/NLP   \n",
       "6  Data analytics / Data scientist intern (work f...   \n",
       "7              Chaayos is Looking For Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9       We are hiring- Data Scientist +Python- Noida   \n",
       "\n",
       "                                            Location Experience Required  \\\n",
       "0               Noida, Gurgaon/Gurugram, Delhi / NCR             0-0 Yrs   \n",
       "1  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...             0-3 Yrs   \n",
       "2                                              Noida             3-5 Yrs   \n",
       "3                                   Gurgaon/Gurugram             2-6 Yrs   \n",
       "4                                              Noida             3-8 Yrs   \n",
       "5                                   Gurgaon/Gurugram             2-4 Yrs   \n",
       "6          Kolkata, Bangalore/Bengaluru, Delhi / NCR             0-5 Yrs   \n",
       "7                                          New Delhi             0-5 Yrs   \n",
       "8      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru             3-7 Yrs   \n",
       "9               Noida, Gurgaon/Gurugram, Delhi / NCR             4-7 Yrs   \n",
       "\n",
       "                                 Company  \n",
       "0              GABA Consultancy services  \n",
       "1     Inflexion Analytix Private Limited  \n",
       "2            Acidaes Solutions Pvt. Ltd.  \n",
       "3                                 TalPro  \n",
       "4  NEC CORPORATION INDIA PRIVATE LIMITED  \n",
       "5                                 TalPro  \n",
       "6                         TalkValley LLC  \n",
       "7  Chaayos (Sunshine Teahouse Pvt. Ltd.)  \n",
       "8                      Fractal Analytics  \n",
       "9                 RANDSTAD INDIA PVT LTD  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = pd.DataFrame({})\n",
    "jobs[\"Job Title\"] = job_titles\n",
    "jobs[\"Location\"] = locations\n",
    "jobs[\"Experience Required\"] = exp\n",
    "jobs[\"Company\"] = comp_name\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4): Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida”\n",
    "in “location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown\n",
    "page.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_des = driver.find_element_by_id(\"scKeyword\")\n",
    "search_des.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_loc = driver.find_element_by_id(\"scLocation\")\n",
    "search_loc.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_click = driver.find_element_by_xpath(\"//button[@class='pl-0 pr-xsm SearchStyles__searchKeywordSubmit']\")\n",
    "search_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_name = driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']//span\")\n",
    "name = []\n",
    "for i in comp_name:\n",
    "    name.append(i.text)\n",
    "len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['16d', '30d+', '20d', '12d', '2d', '30d+', '30d+', '6d', '13d', '30d+']\n",
      "Ratings - \n",
      " ['3.0', '3.9', '4.1', '3.8', '4.3', '5.0', '4.1', '3.8', '3.1', '3.7']\n"
     ]
    }
   ],
   "source": [
    "nodays = driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "days = []\n",
    "for i in nodays:\n",
    "    days.append(i.text)\n",
    "rate = driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\")\n",
    "rating = []\n",
    "for j in rate:\n",
    "    rating.append(j.text)\n",
    "print(days[:10])\n",
    "print(\"Ratings - \\n\",rating[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = name[:10]\n",
    "days = days[:10]\n",
    "rating = rating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No. of days since posted</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Patterns</td>\n",
       "      <td>16d</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ginger Webs Pvt. Ltd.</td>\n",
       "      <td>20d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Siemens Technology and Services Private Limited</td>\n",
       "      <td>12d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Innovacer</td>\n",
       "      <td>2d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MasterCard</td>\n",
       "      <td>30d+</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wobb.ai</td>\n",
       "      <td>6d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Algo8 AI Pvt. Ltd.</td>\n",
       "      <td>13d</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Company Name No. of days since posted  \\\n",
       "0                                    Data Patterns                      16d   \n",
       "1                                   Biz2Credit Inc                     30d+   \n",
       "2                            Ginger Webs Pvt. Ltd.                      20d   \n",
       "3  Siemens Technology and Services Private Limited                      12d   \n",
       "4                                        Innovacer                       2d   \n",
       "5                                       MasterCard                     30d+   \n",
       "6                     Salasar New Age Technologies                     30d+   \n",
       "7                                          Wobb.ai                       6d   \n",
       "8                               Algo8 AI Pvt. Ltd.                      13d   \n",
       "9                                         Techlive                     30d+   \n",
       "\n",
       "  Rating  \n",
       "0    3.0  \n",
       "1    3.9  \n",
       "2    4.1  \n",
       "3    3.8  \n",
       "4    4.3  \n",
       "5    5.0  \n",
       "6    4.1  \n",
       "7    3.8  \n",
       "8    3.1  \n",
       "9    3.7  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_posted = pd.DataFrame({})\n",
    "job_posted[\"Company Name\"] = name\n",
    "job_posted[\"No. of days since posted\"] = days\n",
    "job_posted[\"Rating\"] = rating\n",
    "job_posted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5): Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "   *You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, companyname, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_des = driver.find_element_by_id(\"KeywordSearch\")\n",
    "search_des.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_loc = driver.find_element_by_id(\"LocationSearch\")\n",
    "search_loc.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_click = driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\")\n",
    "search_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IBM', 'Tata Consultancy Services', 'Accenture', 'Delhivery', 'Ericsson-Worldwide', 'UnitedHealth Group', 'Valiance Solutions', 'Optum Global Solutions', 'ZS Associates', 'EXL Service', 'Optum', 'Innovaccer', 'Cognizant Technology Solutions', 'Nagarro', 'dunnhumby', 'Vidooly Media Tech', 'Tech Mahindra', 'OYO', 'R Systems', 'CARS24.com']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Range:', '₹6L', '-', '₹27L'],\n",
       " ['Range:', '₹3L', '-', '₹13L'],\n",
       " ['Range:', '₹6L', '-', '₹22L'],\n",
       " ['Range:', '₹5L', '-', '₹1Cr'],\n",
       " ['Range:', '₹4L', '-', '₹16L'],\n",
       " ['Range:', '₹11L', '-', '₹15L'],\n",
       " ['Range:', '₹5L', '-', '₹15L'],\n",
       " ['Range:', '₹4L', '-', '₹22L'],\n",
       " ['Range:', '₹2L', '-', '₹18L'],\n",
       " ['Range:', '₹6L', '-', '₹15L'],\n",
       " ['Range:', '₹8L', '-', '₹20L'],\n",
       " ['Range:', '₹6L', '-', '₹17L'],\n",
       " ['Range:', '₹8L', '-', '₹13L'],\n",
       " ['Range:', '₹4L', '-', '₹16L'],\n",
       " ['Range:', '₹8L', '-', '₹20L'],\n",
       " ['Range:', '₹12T', '-', '₹63T'],\n",
       " ['Range:', '₹4L', '-', '₹17L'],\n",
       " ['Range:', '₹10L', '-', '₹19L'],\n",
       " ['Range:', '₹8L', '-', '₹30L'],\n",
       " ['Range:', '₹9L', '-', '₹15L']]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name = driver.find_elements_by_xpath(\"//h3[@class='m-0 css-g261rn']//a\")\n",
    "name = []\n",
    "min_salary = []\n",
    "for i in company_name:\n",
    "    name.append(i.text)\n",
    "print(name)\n",
    "min_sal =driver.find_elements_by_xpath(\"//span[@class='d-block d-lg-none m-0 css-1b6bxoo']\")\n",
    "for i in min_sal:\n",
    "    min_salary.append(i.text)\n",
    "minimum_salary = []\n",
    "for j in range(0,len(min_salary)):\n",
    "    minimum_salary.append(min_salary[j].split())\n",
    "minimum_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['₹6L', '₹3L', '₹6L', '₹5L', '₹4L', '₹11L', '₹5L', '₹4L', '₹2L', '₹6L']\n",
      "['₹27L', '₹13L', '₹22L', '₹1Cr', '₹16L', '₹15L', '₹15L', '₹22L', '₹18L', '₹15L']\n"
     ]
    }
   ],
   "source": [
    "low_salary = []\n",
    "for i in range(0,len(minimum_salary)):\n",
    "    for j in range(1,2):\n",
    "        low_salary.append(minimum_salary[i][j])\n",
    "low_salary\n",
    "max_salary = []\n",
    "for i in range(0,len(minimum_salary)):\n",
    "    for j in range(3,4):\n",
    "        max_salary.append(minimum_salary[i][j])\n",
    "print(low_salary[:10])\n",
    "print(max_salary[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['₹9,00,000', '₹6,15,289', '₹11,63,336', '₹12,18,244', '₹7,39,238', '₹13,38,279', '₹8,63,750', '₹13,28,697', '₹11,42,356', '₹11,46,073']\n",
      "['3.9', '3.9', '4', '3.9', '4', '3.7', '4.2', '3.9', '4', '3.6']\n"
     ]
    }
   ],
   "source": [
    "avg = driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']//h3\")\n",
    "avg_sal = []\n",
    "for i in avg:\n",
    "    avg_sal.append(i.text)\n",
    "print(avg_sal[:10])\n",
    "rate = driver.find_elements_by_xpath(\"//span[@class='m-0 css-kyx745']\")\n",
    "rating = []\n",
    "for i in rate:\n",
    "    rating.append(i.text)\n",
    "print(rating[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = name[:10]\n",
    "low_salary = low_salary[:10]\n",
    "max_salary = max_salary[:10]\n",
    "rating = rating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sal = avg_sal[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹27L</td>\n",
       "      <td>₹9,00,000</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹3L</td>\n",
       "      <td>₹13L</td>\n",
       "      <td>₹6,15,289</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹22L</td>\n",
       "      <td>₹11,63,336</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹1Cr</td>\n",
       "      <td>₹12,18,244</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>₹7,39,238</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹11L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹13,38,279</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹8,63,750</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹22L</td>\n",
       "      <td>₹13,28,697</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹2L</td>\n",
       "      <td>₹18L</td>\n",
       "      <td>₹11,42,356</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹11,46,073</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company Minimum Salary Maximum Salary Average Salary  \\\n",
       "0                        IBM            ₹6L           ₹27L      ₹9,00,000   \n",
       "1  Tata Consultancy Services            ₹3L           ₹13L      ₹6,15,289   \n",
       "2                  Accenture            ₹6L           ₹22L     ₹11,63,336   \n",
       "3                  Delhivery            ₹5L           ₹1Cr     ₹12,18,244   \n",
       "4         Ericsson-Worldwide            ₹4L           ₹16L      ₹7,39,238   \n",
       "5         UnitedHealth Group           ₹11L           ₹15L     ₹13,38,279   \n",
       "6         Valiance Solutions            ₹5L           ₹15L      ₹8,63,750   \n",
       "7     Optum Global Solutions            ₹4L           ₹22L     ₹13,28,697   \n",
       "8              ZS Associates            ₹2L           ₹18L     ₹11,42,356   \n",
       "9                EXL Service            ₹6L           ₹15L     ₹11,46,073   \n",
       "\n",
       "  Rating  \n",
       "0    3.9  \n",
       "1    3.9  \n",
       "2      4  \n",
       "3    3.9  \n",
       "4      4  \n",
       "5    3.7  \n",
       "6    4.2  \n",
       "7    3.9  \n",
       "8      4  \n",
       "9    3.6  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary = pd.DataFrame()\n",
    "salary[\"Company\"] = name\n",
    "salary[\"Minimum Salary\"] = low_salary\n",
    "salary[\"Maximum Salary\"] = max_salary\n",
    "salary[\"Average Salary\"] = avg_sal\n",
    "salary[\"Rating\"] = rating\n",
    "salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6)Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and\n",
    "more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page\n",
    "you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of\n",
    "the page , then click on it\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_product = driver.find_element_by_xpath(\"//div[@class='col-12-12 _2oO9oE']//input\")\n",
    "search_product.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_search = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "click_search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brands = []\n",
    "for i in brand_name:\n",
    "    brands.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = driver.find_elements_by_xpath(\"//div[@class='_2B099V']//a\")\n",
    "description = []\n",
    "for i in desc:\n",
    "    description.append(i.text)\n",
    "descriptions =[]\n",
    "for j in range(0,len(description),2):\n",
    "    descriptions.append(description[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_get = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "price = []\n",
    "for i in price_get:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_percent = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "discount = []\n",
    "for i in discount_percent:\n",
    "    discount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page = driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name1 = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brands1 = []\n",
    "for i in brand_name1:\n",
    "    brands1.append(i.text)\n",
    "for j in brands1:\n",
    "    brands.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = driver.find_elements_by_xpath(\"//div[@class='_2B099V']//a\")\n",
    "description1 = []\n",
    "for i in desc:\n",
    "    description1.append(i.text)\n",
    "descriptions1 =[]\n",
    "for j in range(0,len(description1),2):\n",
    "    descriptions1.append(description1[j])\n",
    "for k in descriptions1:\n",
    "    descriptions.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_get = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "price1 = []\n",
    "for i in price_get:\n",
    "    price1.append(i.text)\n",
    "for j in price1:\n",
    "    price.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_percent = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "discount1 = []\n",
    "for i in discount_percent:\n",
    "    discount1.append(i.text)\n",
    "for j in discount1:\n",
    "    discount.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page1 = driver.find_element_by_xpath(\"/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]\")\n",
    "next_page1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name2 = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brands2 = []\n",
    "for i in brand_name2:\n",
    "    brands2.append(i.text)\n",
    "for j in brands2:\n",
    "    brands.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = driver.find_elements_by_xpath(\"//div[@class='_2B099V']//a\")\n",
    "description2 = []\n",
    "for i in desc:\n",
    "    description2.append(i.text)\n",
    "descriptions2 =[]\n",
    "for j in range(0,len(description2),2):\n",
    "    descriptions2.append(description2[j])\n",
    "for k in descriptions2:\n",
    "    descriptions.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_get = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "price2 = []\n",
    "for i in price_get:\n",
    "    price2.append(i.text)\n",
    "for j in price2:\n",
    "    price.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_percent = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "discount2 = []\n",
    "for i in discount_percent:\n",
    "    discount2.append(i.text)\n",
    "for j in discount2:\n",
    "    discount.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = brands[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = descriptions[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = price[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount = discount[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Wayfarer Sunglasses ...</td>\n",
       "      <td>₹1,120</td>\n",
       "      <td>43% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized Round Sunglasses (56)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹349</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹509</td>\n",
       "      <td>36% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Over-sized Sunglasses ...</td>\n",
       "      <td>₹917</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fravy</td>\n",
       "      <td>UV Protection, Gradient, Night Vision Retro Sq...</td>\n",
       "      <td>₹296</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (32)</td>\n",
       "      <td>₹237</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Gradient, Night Vision, Mirrore...</td>\n",
       "      <td>₹335</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Oval Sunglasses (58)</td>\n",
       "      <td>₹543</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description   Price  \\\n",
       "0    VINCENT CHASE  by Lenskart UV Protection Wayfarer Sunglasses ...  ₹1,120   \n",
       "1    VINCENT CHASE                    Polarized Round Sunglasses (56)    ₹799   \n",
       "2   kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...    ₹299   \n",
       "3   kingsunglasses         UV Protection Round Sunglasses (Free Size)    ₹349   \n",
       "4         Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...    ₹509   \n",
       "..             ...                                                ...     ...   \n",
       "95          AISLIN  UV Protection, Gradient Over-sized Sunglasses ...    ₹917   \n",
       "96           Fravy  UV Protection, Gradient, Night Vision Retro Sq...    ₹296   \n",
       "97          PIRASO             UV Protection Wayfarer Sunglasses (32)    ₹237   \n",
       "98           NuVew  UV Protection, Gradient, Night Vision, Mirrore...    ₹335   \n",
       "99          AISLIN                 UV Protection Oval Sunglasses (58)    ₹543   \n",
       "\n",
       "   Discount  \n",
       "0   43% off  \n",
       "1   60% off  \n",
       "2   88% off  \n",
       "3   78% off  \n",
       "4   36% off  \n",
       "..      ...  \n",
       "95  77% off  \n",
       "96  85% off  \n",
       "97  85% off  \n",
       "98  70% off  \n",
       "99  78% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunglasses = pd.DataFrame({})\n",
    "sunglasses[\"Brand\"] = brands\n",
    "sunglasses[\"Description\"] = descriptions\n",
    "sunglasses[\"Price\"] = price\n",
    "sunglasses[\"Discount\"] = discount\n",
    "sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7): Scrape 100 reviews data from flipkart.com for iphone11 phone. You have togo the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_click = driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\")\n",
    "button_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=1',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=2',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=3',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=4',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=5',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=6',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=7',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=8',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=9',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=10',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=2']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = driver.find_elements_by_xpath(\"//div[@class='_2MImiq _1Qnn1K']//a\")\n",
    "page_url = []\n",
    "for i in urls:\n",
    "    page_url.append(i.get_attribute('href'))\n",
    "page_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = []\n",
    "for j in page_url:\n",
    "    driver.get(j)\n",
    "    rate = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    for j in rate:\n",
    "        rating.append(j.text)\n",
    "len(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = rating[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_summary = []\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    review_sum = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    for i in review_sum:\n",
    "        review_summary.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_summary = review_summary[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_review = []\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    full_rev = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    for i in full_rev:\n",
    "        full_review.append(i.text)\n",
    "len(full_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_review = full_review[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>We are on apple ecosystem for almost eight yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>A perfect phone and a good battery super camer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>i was confused between 11 and 11 pro. i was go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Product is nice at the deviled time the delive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>The best all rounder iphone. Flipkart is doing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings         Review Summary  \\\n",
       "0        5              Brilliant   \n",
       "1        5       Perfect product!   \n",
       "2        5          Great product   \n",
       "3        5      Worth every penny   \n",
       "4        5              Fabulous!   \n",
       "..     ...                    ...   \n",
       "95       5         Classy product   \n",
       "96       5              Excellent   \n",
       "97       5  Mind-blowing purchase   \n",
       "98       5              Fabulous!   \n",
       "99       5    Best in the market!   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  We are on apple ecosystem for almost eight yea...  \n",
       "96  A perfect phone and a good battery super camer...  \n",
       "97  i was confused between 11 and 11 pro. i was go...  \n",
       "98  Product is nice at the deviled time the delive...  \n",
       "99  The best all rounder iphone. Flipkart is doing...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone_ratings = pd.DataFrame({})\n",
    "iphone_ratings[\"Ratings\"] = rating\n",
    "iphone_ratings[\"Review Summary\"] = review_summary\n",
    "iphone_ratings[\"Full Review\"] = full_review\n",
    "iphone_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8)Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']//input\")\n",
    "search_bar.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']//a\")\n",
    "page_url = []\n",
    "for i in urls:\n",
    "    page_url.append(i.get_attribute('href'))\n",
    "page_url = page_url[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=1',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=2',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=3']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand length :  120\n"
     ]
    }
   ],
   "source": [
    "brand = []\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    brandname = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for j in brandname:\n",
    "        brand.append(j.text)\n",
    "\n",
    "print(\"Brand length : \",len(brand))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description length :  120\n",
      "['Sneakers For Men', 'Sneakers For Men', 'Modern Trendy Shoes Combo pack of 4 Sneakers For Men', 'Casual Sneakers Shoes For Men Sneakers For Men', 'Shoes in Black Color Party wear/Outdoor/Casual Shoes Fo...']\n"
     ]
    }
   ],
   "source": [
    "descriptions = []\n",
    "description = []\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    desc = driver.find_elements_by_xpath(\"//div[@class='_2B099V']//a\")\n",
    "    for k in desc:\n",
    "        descriptions.append(k.text)\n",
    "for t in range(0,len(descriptions),2):\n",
    "        description.append(descriptions[t])\n",
    "    \n",
    "print(\"Description length : \",len(description))    \n",
    "print(description[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price length :  120\n",
      "Discount length : 120\n",
      "['₹699', '₹399', '₹748'] \n",
      "\n",
      "['65% off', '77% off', '62% off']\n"
     ]
    }
   ],
   "source": [
    "price = []\n",
    "discount = []\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    pr = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    for l in pr:\n",
    "        price.append(l.text)\n",
    "    dis = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "    for s in dis:\n",
    "        discount.append(s.text)\n",
    "print(\"Price length : \",len(price))\n",
    "print(\"Discount length :\",len(discount))\n",
    "print(price[:3],\"\\n\")\n",
    "print(discount[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = brand[:100]\n",
    "description = description[:100]\n",
    "price = price[:100]\n",
    "discount = discount[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(description),len(price),len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French Connection</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹699</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tigonis</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALCADOS</td>\n",
       "      <td>Modern Trendy Shoes Combo pack of 4 Sneakers F...</td>\n",
       "      <td>₹748</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alfiya</td>\n",
       "      <td>Shoes in Black Color Party wear/Outdoor/Casual...</td>\n",
       "      <td>₹377</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Echor</td>\n",
       "      <td>Unique &amp; Perfect Collection Combo Pack of 02 S...</td>\n",
       "      <td>₹565</td>\n",
       "      <td>43% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NIKE</td>\n",
       "      <td>Simha IDP Sneakers For Men</td>\n",
       "      <td>₹1,397</td>\n",
       "      <td>53% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Bonexy</td>\n",
       "      <td>PRO-NP-AW08 Sneakers For Men</td>\n",
       "      <td>₹586</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,366</td>\n",
       "      <td>59% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>HHM Sneakers For Men</td>\n",
       "      <td>₹470</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand Name                                        Description  \\\n",
       "0   French Connection                                   Sneakers For Men   \n",
       "1             tigonis                                   Sneakers For Men   \n",
       "2            CALCADOS  Modern Trendy Shoes Combo pack of 4 Sneakers F...   \n",
       "3        Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "4              Alfiya  Shoes in Black Color Party wear/Outdoor/Casual...   \n",
       "..                ...                                                ...   \n",
       "95              Echor  Unique & Perfect Collection Combo Pack of 02 S...   \n",
       "96               NIKE                         Simha IDP Sneakers For Men   \n",
       "97             Bonexy                       PRO-NP-AW08 Sneakers For Men   \n",
       "98               FILA                                   Sneakers For Men   \n",
       "99       Robbie jones                               HHM Sneakers For Men   \n",
       "\n",
       "     Price Discount  \n",
       "0     ₹699  65% off  \n",
       "1     ₹399  77% off  \n",
       "2     ₹748  62% off  \n",
       "3     ₹379  62% off  \n",
       "4     ₹377  62% off  \n",
       "..     ...      ...  \n",
       "95    ₹565  43% off  \n",
       "96  ₹1,397  53% off  \n",
       "97    ₹586  72% off  \n",
       "98  ₹1,366  59% off  \n",
       "99    ₹470  68% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakers = pd.DataFrame({})\n",
    "sneakers[\"Brand Name\"] = brand\n",
    "sneakers[\"Description\"] = description\n",
    "sneakers[\"Price\"] = price\n",
    "sneakers[\"Discount\"] = discount\n",
    "sneakers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9)Go to the link - https://www.myntra.com/shoes Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.myntra.com/shoes\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_filter = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_filter = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "color_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the links of the inner pages\n",
    "next_page_url = driver.find_elements_by_xpath(\"//div[@class='results-showMoreContainer']//a\")\n",
    "next_pages = []\n",
    "for i in next_page_url:\n",
    "    next_pages.append(i.get_attribute(\"href\"))\n",
    "next_pages = next_pages[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand = []\n",
    "for i in next_pages:\n",
    "    driver.get(i)\n",
    "    brand_name = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    for j in brand_name:\n",
    "        brand.append(j.text)\n",
    "len(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nike', 'Nike', 'ALDO', 'Nike', 'Nike']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Men Sneakers',\n",
       " 'Unisex LEBRON XVIII Basketball',\n",
       " 'Men AIR ZOOM Running Shoes',\n",
       " 'Men Zoom Winflo 8 Running',\n",
       " 'Men AIR ZOOM PEGASUS 38 Run']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = []\n",
    "for i in next_pages:\n",
    "    driver.get(i)\n",
    "    description_short = driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']//h4\")\n",
    "    for j in description_short:\n",
    "        description.append(j.text)\n",
    "descriptions = []\n",
    "for k in range(0,len(description),2):\n",
    "    descriptions.append(description[k])\n",
    "descriptions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rs. 9995',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7721Rs. 10295(25% OFF)',\n",
       " 'Rs. 10557Rs. 17595( 40 % OFF)',\n",
       " 'Rs. 8295']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = []\n",
    "for i in next_pages:\n",
    "    driver.get(i)\n",
    "    price_view = driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    for j in price_view:\n",
    "        price.append(j.text)\n",
    "price[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = brand[:100]\n",
    "descriptions = descriptions[:100]\n",
    "price = price[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>Rs. 9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Unisex LEBRON XVIII Basketball</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 7721Rs. 10295(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Zoom Winflo 8 Running</td>\n",
       "      <td>Rs. 10557Rs. 17595( 40 % OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM PEGASUS 38 Run</td>\n",
       "      <td>Rs. 8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men RENEW FUSION Running Shoes</td>\n",
       "      <td>Rs. 6995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Women Sneakers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Woven Design Slip-On Sneakers</td>\n",
       "      <td>Rs. 11990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Women Glossy Pumps</td>\n",
       "      <td>Rs. 7799Rs. 11999(35% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Supernova+ Running</td>\n",
       "      <td>Rs. 6749Rs. 14999(55% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand                          Description  \\\n",
       "0        Nike                         Men Sneakers   \n",
       "1        Nike       Unisex LEBRON XVIII Basketball   \n",
       "2        ALDO           Men AIR ZOOM Running Shoes   \n",
       "3        Nike            Men Zoom Winflo 8 Running   \n",
       "4        Nike          Men AIR ZOOM PEGASUS 38 Run   \n",
       "..        ...                                  ...   \n",
       "95       Nike       Men RENEW FUSION Running Shoes   \n",
       "96       FILA                       Women Sneakers   \n",
       "97       Geox  Women Woven Design Slip-On Sneakers   \n",
       "98     ADIDAS                   Women Glossy Pumps   \n",
       "99  Cole Haan             Women Supernova+ Running   \n",
       "\n",
       "                            Price  \n",
       "0                        Rs. 9995  \n",
       "1                        Rs. 9999  \n",
       "2      Rs. 7721Rs. 10295(25% OFF)  \n",
       "3   Rs. 10557Rs. 17595( 40 % OFF)  \n",
       "4                        Rs. 8295  \n",
       "..                            ...  \n",
       "95                       Rs. 6995  \n",
       "96                       Rs. 8999  \n",
       "97                      Rs. 11990  \n",
       "98     Rs. 7799Rs. 11999(35% OFF)  \n",
       "99     Rs. 6749Rs. 14999(55% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes = pd.DataFrame({})\n",
    "shoes[\"Brand\"] = brand\n",
    "shoes[\"Description\"] = descriptions\n",
    "shoes[\"Price\"] = price\n",
    "shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10)Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon.Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes\n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_laptop = driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search_laptop.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_click = driver.find_element_by_xpath(\"//div[@class='nav-search-submit nav-sprite']//input\")\n",
    "search_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpufilter1 = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div/div[2]/div/div[3]/span/div[1]/span/div/div/div[5]/ul[1]/li[26]/span/a/div/label/i\")\n",
    "cpufilter1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpufilter2 = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div/div[2]/div/div[3]/span/div[1]/span/div/div/div[5]/ul[1]/li[28]/span/a/div/label/i\")\n",
    "cpufilter2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "tit = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in tit:\n",
    "    title.append(i.text)\n",
    "len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = []\n",
    "pr = driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in pr:\n",
    "    price.append(i.text)\n",
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = price[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.amazon.in/gp/slredirect/picassoRedirect.html/ref=pa_sp_atf_computers_sr_pg1_1?ie=UTF8&adId=A09927331AQANGH5N8P79&url=%2FLenovo-Legion-Windows-Graphics-81YU0029IN%2Fdp%2FB087D48PYW%2Fref%3Dsr_1_1_sspa%3Fdchild%3D1%26keywords%3DLaptop%26qid%3D1625222267%26refinements%3Dp_n_feature_thirteen_browse-bin%253A12598163031%257C16757432031%26rnid%3D12598141031%26s%3Dcomputers%26sr%3D1-1-spons%26psc%3D1&qualifier=1625222267&id=2892043441041836&widgetName=sp_atf',\n",
       " 'https://www.amazon.in/gp/slredirect/picassoRedirect.html/ref=pa_sp_atf_computers_sr_pg1_1?ie=UTF8&adId=A02653902UKZ2EJPLDFRL&url=%2FNotebook-Horizon-i5-10210U-Graphics-XMA1904-AR%2Fdp%2FB089F5JGM1%2Fref%3Dsr_1_2_sspa%3Fdchild%3D1%26keywords%3DLaptop%26qid%3D1625222267%26refinements%3Dp_n_feature_thirteen_browse-bin%253A12598163031%257C16757432031%26rnid%3D12598141031%26s%3Dcomputers%26sr%3D1-2-spons%26psc%3D1&qualifier=1625222267&id=2892043441041836&widgetName=sp_atf',\n",
       " 'https://www.amazon.in/HP-Pavilion-Graphics-35-56cms-14-dv0058TU/dp/B08WB857GB/ref=sr_1_3?dchild=1&keywords=Laptop&qid=1625222267&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-3',\n",
       " 'https://www.amazon.in/Dell-35-56cms-1366x768-Integrated-Graphics/dp/B097PL7VX8/ref=sr_1_4?dchild=1&keywords=Laptop&qid=1625222267&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-4',\n",
       " 'https://www.amazon.in/MSI-i7-10750H-IPS-Level-Windows-10SCXR-654IN/dp/B093L8QGL7/ref=sr_1_5?dchild=1&keywords=Laptop&qid=1625222267&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-5']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_url = []\n",
    "pages = driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "for i in pages:\n",
    "    page_url.append(i.get_attribute('href'))\n",
    "page_url[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        laptop_rating = driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']//span\")\n",
    "        rating.append(laptop_rating.text)\n",
    "    except:\n",
    "        pass\n",
    "rating = rating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.8', '4.4', '4.5', '4.4', '3.9', '4.1', '4', '3.1', '4.3', '5']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = []\n",
    "for i in rating:\n",
    "    ratings+=i.split(' ')\n",
    "ratings\n",
    "laptop_rating = []\n",
    "for j in range(0,len(ratings),4):\n",
    "    laptop_rating.append(ratings[j])\n",
    "laptop_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating(Out of 5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo Legion 7 10th Gen Intel Core i7 15.6 in...</td>\n",
       "      <td>1,49,990</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>54,999</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>84,990</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...</td>\n",
       "      <td>46,999</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm...</td>\n",
       "      <td>78,640</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...</td>\n",
       "      <td>42,999</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>59,999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...</td>\n",
       "      <td>78,993</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...</td>\n",
       "      <td>41,999</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>86,990</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price  \\\n",
       "0  Lenovo Legion 7 10th Gen Intel Core i7 15.6 in...  1,49,990   \n",
       "1  Mi Notebook Horizon Edition 14 Intel Core i5-1...    54,999   \n",
       "2  HP Pavilion (2021) Thin & Light 11th Gen Core ...    84,990   \n",
       "3  (Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...    46,999   \n",
       "4  MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm...    78,640   \n",
       "5  (Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...    42,999   \n",
       "6  Mi Notebook Horizon Edition 14 Intel Core i7-1...    59,999   \n",
       "7  HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...    78,993   \n",
       "8  (Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...    41,999   \n",
       "9  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...    86,990   \n",
       "\n",
       "  Rating(Out of 5)  \n",
       "0              3.8  \n",
       "1              4.4  \n",
       "2              4.5  \n",
       "3              4.4  \n",
       "4              3.9  \n",
       "5              4.1  \n",
       "6                4  \n",
       "7              3.1  \n",
       "8              4.3  \n",
       "9                5  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop = pd.DataFrame({})\n",
    "laptop[\"Title\"] = title\n",
    "laptop[\"Price\"] = price\n",
    "laptop[\"Rating(Out of 5)\"] = laptop_rating\n",
    "laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
